{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "early-science",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "torch.cuda.init()\n",
    "if torch.cuda.get_device_capability()[0] >= 8: # ampere\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True # This flag defaults to False\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "torch.cuda.set_per_process_memory_fraction(0.9) # 限制最高gpu顯存使用率，0-1之間浮點數，1 == 100%\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d-%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-history",
   "metadata": {},
   "source": [
    "## Load flooding configuration file from local device or gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-watch",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ml4floods.models.config_setup import get_default_config\n",
    "import pkg_resources\n",
    "\n",
    "# Set filepath to configuration files\n",
    "# config_fp = 'path/to/worldfloods_template.json'\n",
    "config_fp = pkg_resources.resource_filename(\"ml4floods\",\"models/configurations/worldfloods_template.json\")\n",
    "# 模型名稱\n",
    "\n",
    "config = get_default_config(config_fp)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-scope",
   "metadata": {},
   "source": [
    "## Step 2: Setup Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-edgar",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.experiment_name = 'new_1015' # only_water\n",
    "config.data_params.channel_configuration = 'bgri'\n",
    "config.data_params.batch_size = 24\n",
    "config.model_params.hyperparameters.channel_configuration = 'bgri'\n",
    "config.data_params.window_size = [256,256]\n",
    "config.model_params.hyperparameters.num_channels = 4\n",
    "config.model_params.hyperparameters.max_tile_size = 256\n",
    "config.data_params.bucket_id = \"\"\n",
    "config.model_params.hyperparameters.metric_monitor = 'val_dice_loss'\n",
    "config.model_params.hyperparameters.weight_per_class = [1.93445299, 36.60054169, 2.19400729] \n",
    "# config.model_params.hyperparameters.weight_per_class = [1.0, 1.0, 1.0] \n",
    "\n",
    "# config.data_params.target_folder = 'gt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-musician",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# from ml4.dataset_setup import get_dataset\n",
    "from ml4floods.models.dataset_setup import get_dataset\n",
    "config.data_params.batch_size = 40 # control this depending on the space on your GPU! Hint: 8 with log, max about 20\n",
    "config.data_params.loader_type = 'local'\n",
    "config.data_params.path_to_splits = \"/mnt/d/Flooding//worldfloods_v1_0\" # local folder to download the data\n",
    "config.data_params.train_test_split_file = \"/mnt/d/Flooding/train_test_split.json\"\n",
    "config.data_params[\"download\"] = {\"train\": True, \"val\": True, \"test\": True} # download only test data\n",
    "# config.data_params.train_test_split_file = \"2_PROD/2_Mart/worldfloods_v1_0/train_test_split.json\" # use this to train with all the data\n",
    "config.data_params.num_workers = 16\n",
    "\n",
    "# If files are not in config.data_params.path_to_splits this will trigger the download of the products.\n",
    "dataset = get_dataset(config.data_params)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-harassment",
   "metadata": {},
   "source": [
    "## Verfify data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-driver",
   "metadata": {},
   "source": [
    "#### Verify training data\n",
    "Data format here: https://github.com/spaceml-org/ml4floods/blob/891fe602880586e7ac821d2f282bf5ec9d4c0795/ml4floods/data/worldfloods/dataset.py#L106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-harbor",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl = dataset.train_dataloader()\n",
    "train_dl_iter = iter(train_dl)\n",
    "print(len(train_dl_iter))\n",
    "batch_train = next(train_dl_iter)\n",
    "\n",
    "batch_train[\"image\"].shape, batch_train[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-spanking",
   "metadata": {},
   "source": [
    "Verify validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-effect",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dl = dataset.val_dataloader()\n",
    "\n",
    "val_dl_iter = iter(val_dl)\n",
    "print(len(val_dl_iter))\n",
    "batch_val = next(val_dl_iter)\n",
    "\n",
    "batch_val[\"image\"].shape, batch_val[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-multiple",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dl = dataset.test_dataloader()\n",
    "\n",
    "test_dl_iter = iter(test_dl)\n",
    "print(len(test_dl_iter))\n",
    "\n",
    "batch_test = next(test_dl_iter)\n",
    "batch_test[\"image\"].shape, batch_test[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-electron",
   "metadata": {},
   "source": [
    "### Plot batch by using ml4flood model \n",
    "check detail here: https://github.com/spaceml-org/ml4floods/blob/891fe602880586e7ac821d2f282bf5ec9d4c0795/ml4floods/data/worldfloods/dataset.py#L106"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bridal-needle",
   "metadata": {},
   "source": [
    "from models import flooding_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flooding_model.plot_batch(batch_train[\"image\"])\n",
    "\n",
    "n_images=6\n",
    "fig, axs = plt.subplots(3,n_images, figsize=(18,10),tight_layout=True)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_train[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],\n",
    "                             axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_train[\"mask\"][:n_images, 0],axs=axs[2], show_axis=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba1c214-d7aa-4f94-b099-b617cc19558f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from models import flooding_model\n",
    "flooding_model = importlib.reload(flooding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-cleanup",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3: Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-surrey",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # folder to store the trained model (it will create a subfolder with the name of the experiment)\n",
    "config.model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-tiffany",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.model_params.model_folder = \"train_models\" \n",
    "os.makedirs(\"train_models\", exist_ok=True)\n",
    "config.model_params.test = False\n",
    "config.model_params.train = True\n",
    "config.model_params.hyperparameters.model_type = \"res2vtunet\" \n",
    "# Currently implemented: unet2, unet_xception, unet_3+, unet_3+_deepsub, unet_s2, unet_sep_s2, hunet\n",
    "# res2_unet, res2_daunet, attunet, res2_attunet, daunet, res2_saunet, res2rdn_attunet, res2_attunet_sup, simp_res2unet\n",
    "# Transformer: transunet, cvtunet, res2vtunet, deeplabv3+\n",
    "# Compare: malunet, deeplabv3+, swinunet, mtunet, utnet\n",
    "# config.model_params.hyperparameters.num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-bonus",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from models.flooding_model import WorldFloodsModel, DistilledTrainingModel, WorldFloodsModel2, WorldFloodsModel3,WorldFloodsModel1,WorldFloodsModel0, WorldFloodsModel_Sup, WorldFloodsModel_AdaCh\n",
    "importlib.reload(flooding_model)\n",
    "simple_model_params = copy.deepcopy(config.model_params)\n",
    "simple_model_params['hyperparameters']['model_type']=\"res2vtunet\"\n",
    "\n",
    "# gt ={\"train\": batch_train['mask'], \"val\":batch_val['mask']}\n",
    "# model = DistilledTrainingModel(config.model_params, simple_model_params)\n",
    "# model = WorldFloodsModel(config.model_params)\n",
    "model = WorldFloodsModel_Sup(config.model_params)\n",
    "net = model.network\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c524af-5a95-4eaa-821b-8fce5b62b479",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compuatation complexity of network\n",
    "from ptflops import get_model_complexity_info\n",
    "# torch.ones()返回一個由標量值1填充的張量，其形狀由變量參數size定義\n",
    "# x = torch.ones((config.model_params.hyperparameters.num_channels, \n",
    "#                 config.model_params.hyperparameters.max_tile_size, \n",
    "#                 config.model_params.hyperparameters.max_tile_size))\n",
    "# gt ={\"train\": batch_train['mask'], \"val\":batch_val['mask']}\n",
    "# mask_train = (batch_train['mask'][1:])\n",
    "macs, params = get_model_complexity_info(net, (config.model_params.hyperparameters.num_channels, \n",
    "                config.model_params.hyperparameters.max_tile_size, \n",
    "                config.model_params.hyperparameters.max_tile_size), as_strings=True, print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-stationery",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "setup_weights_and_biases = True #False\n",
    "\n",
    "### new: switch account\n",
    "wandb_switch = True\n",
    "old_api = 'bc1eeeb7d29c933290904edebfb0ec8da6e980fe'\n",
    "new_api = 'add1f4d247a20ee1271f026e3cca5255f4053a61'\n",
    "# key = \"add1f4d247a20ee1271f026e3cca5255f4053a61\"\n",
    "#####\n",
    "\n",
    "if setup_weights_and_biases:\n",
    "\n",
    "\n",
    "    import wandb\n",
    "    from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "    config_wb = {'wandb_entity': 'ntustyuyu',\n",
    "                    'wandb_project': 'new_1012',\n",
    "                    'experiment_name': '32_res2vtunet_dice+biou'}\n",
    "\n",
    "    wandb.login(key = new_api)\n",
    "    wandb.init(name=config_wb['experiment_name'],\n",
    "                project=config_wb['wandb_project'], \n",
    "                entity=config_wb['wandb_entity'])\n",
    "\n",
    "    wandb_logger = WandbLogger(name=config_wb['experiment_name'],\n",
    "                                project=config_wb['wandb_project'], \n",
    "                                entity=config_wb['wandb_entity']\n",
    "                                # resume = 'allow'\n",
    "                              )\n",
    "    \n",
    "\n",
    "###\n",
    "    # if wandb_switch:\n",
    "    #     with open('/home/viplab/.netrc', 'w') as f2:\n",
    "    #         f2.write(f_org)\n",
    "    #         f2.close()\n",
    "#####\n",
    "\n",
    "else:\n",
    "    wandb_logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6bcb0-4343-4131-a43e-90d7abc1bf13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# ModelCheckpoint是Pytorch Lightning中的一个Callback，它就是用于模型缓存的。\n",
    "# 它会监视某个指标，每次指标达到最好的时候，它就缓存当前模型\n",
    "\n",
    "experiment_path = f\"{config.model_params.model_folder}/{config.experiment_name}\"\n",
    "checkpoint_path = f\"{experiment_path}/checkpoint/{config.model_params.hyperparameters.model_type}-{now}\" #checkpoint\n",
    "\n",
    "#clean empty folder\n",
    "import glob\n",
    "folder_list = glob.glob(f\"{experiment_path}/checkpoint/*\")\n",
    "for folder in folder_list:\n",
    "    try:\n",
    "        if not any(os.scandir(folder)):\n",
    "            os.removedirs(folder)\n",
    "    except:\n",
    "        continue\n",
    "if not os.path.isdir(checkpoint_path):\n",
    "    # os.mkdir(checkpoint_path)\n",
    "    os.makedirs(checkpoint_path)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=checkpoint_path, # 模型緩存目錄\n",
    "    save_top_k=True,\n",
    "    verbose=True,\n",
    "    monitor='val_dice_loss', # 我們需要監視的指標\n",
    "    mode='min',\n",
    "#     prefix=''\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_dice_loss',\n",
    "    patience=10,\n",
    "    strict=False,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stop_callback]\n",
    "\n",
    "print(f\"The trained model will be stored in {config.model_params.model_folder}/{config.experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-charity",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "config.gpus = 2 # which gpu to use\n",
    "# config.gpus = None # to not use GPU\n",
    "config.model_params.hyperparameters.max_epochs = 30 # train for maximum 4 epochs\n",
    "# checkpoint_pth = \"/home/viplab/VipLabProjects/yuyu/yuyu_38/train_models/new_1012/checkpoint/res2vtunet-2023-10-12-16:13:48/epoch=22-step=111642.ckpt\"\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    fast_dev_run=False,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    "    default_root_dir=f\"{config.model_params.model_folder}/{config.experiment_name}\",\n",
    "    accumulate_grad_batches=1,\n",
    "    gradient_clip_val=0.0,\n",
    "    auto_lr_find=False,\n",
    "    benchmark=False,\n",
    "    max_epochs=config.model_params.hyperparameters.max_epochs,\n",
    "    check_val_every_n_epoch=config.model_params.hyperparameters.val_every,\n",
    "    strategy='dp',\n",
    "    accelerator='gpu',\n",
    "    devices=config.gpus\n",
    "    # resume_from_checkpoint=checkpoint_pth\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-india",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f0d27a9-6286-4ff9-a4ae-aa98da02ada7",
   "metadata": {},
   "source": [
    "torch.save(model.state_dict(),f\"{experiment_path}/{simple_model_params['hyperparameters']['model_type']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278b5db-1d9e-434d-aa4d-3fa8124cb789",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits= model(batch_val[\"image\"].to(model.device))\n",
    "print(f\"Shape of logits: {logits.shape}\")\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(f\"Shape of probs: {probs.shape}\")\n",
    "prediction = torch.argmax(probs, dim=1).long().cpu()\n",
    "print(f\"Shape of prediction: {prediction.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_params.max_tile_size = config.model_params.hyperparameters.max_tile_size\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ml4floods.models.utils import metrics\n",
    "from ml4floods.models.model_setup import get_model_inference_function\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from models.dataset_rgbih import RGBIH_Dataset\n",
    "\n",
    "model.to(\"cuda\")\n",
    "# print(model[0])\n",
    "# logits, all_loss = model\n",
    "inference_function = get_model_inference_function(model, config, apply_normalization=False, activation=\"softmax\")\n",
    "# print(inference_function.dim)\n",
    "\n",
    "dl = dataset.val_dataloader() # pytorch Dataloader\n",
    "# print(type(dl))\n",
    "thresholds_water = [0,1e-3,1e-2]+np.arange(0.5,.96,.05).tolist() + [.99,.995,.999]\n",
    "\n",
    "mets = metrics.compute_metrics(\n",
    "    dl,  # dl\n",
    "    inference_function, \n",
    "    thresholds_water=thresholds_water, \n",
    "    plot=False, convert_targets=False)\n",
    "\n",
    "label_names = [\"land\", \"water\", \"cloud\"]\n",
    "metrics.plot_metrics(mets, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c4bbe-534f-4d1d-86e2-80db511a4ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(dl.dataset, \"image_files\"):\n",
    "    cems_code = [os.path.basename(f).split(\"_\")[0] for f in dl.dataset.image_files]\n",
    "else:\n",
    "    cems_code = [os.path.basename(f.file_name).split(\"_\")[0] for f in dl.dataset.list_of_windows]\n",
    "\n",
    "iou_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_iou,\n",
    "                                                    label_names=[f\"IoU_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "recall_per_code = pd.DataFrame(metrics.group_confusion(mets[\"confusions\"],cems_code, metrics.calculate_recall,\n",
    "                                                       label_names=[f\"Recall_{l}\"for l in [\"land\", \"water\", \"cloud\"]]))\n",
    "\n",
    "join_data_per_code = pd.merge(recall_per_code,iou_per_code,on=\"code\")\n",
    "join_data_per_code = join_data_per_code.set_index(\"code\")\n",
    "join_data_per_code = join_data_per_code*100\n",
    "print(f\"Mean values across flood events: {join_data_per_code.mean(axis=0).to_dict()}\")\n",
    "join_data_per_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f42f47-ab32-4289-a096-2e242c47b941",
   "metadata": {},
   "source": [
    "model_rgbnir_worldflood_transunet_epoch10# import torch\n",
    "from pytorch_lightning.utilities.cloud_io import atomic_save\n",
    "from ml4floods.models.config_setup import save_json\n",
    "\n",
    "# Save in the cloud and in the wandb logger save dir\n",
    "atomic_save(model.state_dict(), f\"{experiment_path}/model_rgbnir_worldflood_unet3+_epoch20.pt\")\n",
    "# Save cofig file in experiment_path\n",
    "config_file_path = f\"{experiment_path}/config_rgbnir_worldflood_unet3+_epoch20.json\"\n",
    "save_json(config, config_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce11adc9-a807-43b3-ad01-b17280564ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),f\"{experiment_path}/model_rgbnir_worldfloodsup_res2vtunet.pt\")\n",
    "# Save cofig file in experiment_path\n",
    "config_file_path = f\"{experiment_path}/config_rgbnir_worldfloodsup_res2vtunet.json\"\n",
    "import json\n",
    "with open(config_file_path, 'w') as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup_weights_and_biases:\n",
    "    torch.save(model.state_dict(), os.path.join(wandb_logger.save_dir, 'model_rgbnir_worldfloodsup_res2vtunet.pt'))\n",
    "    wandb.save(os.path.join(wandb_logger.save_dir, 'model_rgbnir_worldfloodsup_res2vtunet.pt')) # Copy weights to weights and biases server\n",
    "    wandb.finish()\n",
    "\n",
    "    wandb.login(key = old_api)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbafaab-0986-4de8-98ef-0bfb21c439d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_image_start=0\n",
    "n_images=8\n",
    "count=int(n_images-n_image_start)\n",
    "fig, axs = plt.subplots(4, count, figsize=(18,14),tight_layout=True)\n",
    "importlib.reload(flooding_model)\n",
    "flooding_model.plot_batch(batch_val[\"image\"][n_image_start:n_images],channel_configuration=\"bgri\",axs=axs[0],max_clip_val=3500.)\n",
    "flooding_model.plot_batch(batch_val[\"image\"][n_image_start:n_images],channel_configuration=\"bgri\",bands_show=[\"B8\",\"B8\", \"B8\"],axs=axs[1],max_clip_val=3500.)\n",
    "# flooding_model.plot_batch(batch_val[\"image\"][:n_images],bands_show=[\"B11\",\"B8\", \"B4\"],axs=axs[1],max_clip_val=4500.)\n",
    "flooding_model.plot_batch_output_v1(batch_val[\"mask\"][n_image_start:n_images, 0],axs=axs[2], show_axis=True)\n",
    "flooding_model.plot_batch_output_v1(prediction[n_image_start:n_images] + 1,axs=axs[3], show_axis=True)\n",
    "\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.grid(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
